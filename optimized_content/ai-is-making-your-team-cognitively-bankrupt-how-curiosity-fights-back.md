# AI Is Making Your Team Cognitively Bankrupt — Here's How Curiosity Fights Back

**Title tag:** AI Is Making Your Team Cognitively Bankrupt — How Curiosity Fights Back | Nic Haralambous
**Meta description:** MIT brain scans show AI tools reduce neural connectivity by 47%. Nic Haralambous — entrepreneur, AI product builder, and virtual keynote speaker — explains why curiosity is the antidote to cognitive bankruptcy.
**Target keywords:** AI keynote speaker, AI making us dumber, how to use AI without losing your mind, AI and creativity, AI speaker for corporate events
**Target topic hub:** /topics/ai
**Related keynote:** /keynotes/ai-and-product-building

---

## TL;DR

AI tools are the largest technological shift in decades — but they are making many teams cognitively bankrupt. MIT brain scans show a 47% reduction in neural connectivity among heavy AI users. The solution is not to ban AI. It's to use it differently. AI should amplify human curiosity, not replace it. Teams with a strong cognitive baseline and a curious mindset use AI to get smarter. Teams that outsource their thinking to it get measurably dumber. The difference is curiosity.

---

AI is absolutely the largest technological shift in decades. But it is simply a new tool — much like electricity or gunpowder or the printed word or the internet and websites and social media. We adapt. Humans wield these tools.

As someone who has spent 20+ years building technology businesses and now delivers [virtual keynotes on AI and product building](/speaker), I'm not here to tell you that AI is bad. I build with AI every day. But I am here to tell you something uncomfortable: believe it or not, AI tools are quickly making humans dumber every day.

And I have the brain scans to prove it.

## The MIT Study That Should Terrify Every Leader

A team of MIT researchers used EEG brain scans on 54 participants over four months. The participants were split into three groups. The first group had ChatGPT to answer essay questions. The second group was given search engines like Google. The final group was a brain-only group — no tools at all. They were all asked to answer three essay questions over the course of four months, and their brains were scanned throughout the process.

The results were absolutely shocking.

Brain scans revealed the damage: in AI users, neural connections collapsed from 79 to 42. That is a **47% reduction in neural connectivity**. Imagine if your computer all of a sudden just lost 50% of its ability to compute. That is what is happening to the brains of people who rely on AI to do their thinking.

This isn't opinion. This is measurable brain damage from AI usage.

But there is good news. People with a strong cognitive baseline showed higher neural connectivity when using AI than chronic users who relied on it entirely. In short, a curious mindset promotes psychological flexibility, which is crucial for navigating uncertainty. The AI tools we have should be used to amplify human curiosity, not replace it.

## 83% Can't Remember What They Just Wrote

Here's another number that should keep you up at night. A shocking 83% of ChatGPT users couldn't quote from an essay they wrote minutes earlier. Let that sink in.

Now let's apply that to your work. You spend Monday using AI to build a report. You let it do the thinking and acting for you. You send that report to your colleagues. And that Monday afternoon, you go into a meeting and you will not remember the report. You write something, you hit save, and your brain has forgotten it — because you've outsourced your thinking and acting to GPT.

Your action is not asking AI to do the work. That is unfulfilling. It produces nothing in your brain. No neural pathways are strengthened. No learning occurs. No curiosity is sparked. You've simply moved information from one place to another without ever engaging with it.

This is what I call **work slop** — lazy people abusing AI tools to record meetings, to make meeting notes from meeting recordings, and then to make meeting action plans that AI tells you what to do in the next standup. And then you over-align and you over-plan and you under-deliver while blaming everybody but yourselves. The work around the work becomes the work. Box-ticking replaces meaningful progress.

## If Everybody Has the Same Tools, the Tools Are Not the Differentiator

Let me ask you a question that is not rhetorical: does the tool make the team, or does the team make the tool?

If everybody is using the same tools, then the tools are not a differentiator. Do you feel like using Excel gives you a leg up over your competition? Do you feel like using Microsoft Word makes you better than your competition? How about browsing Wikipedia or Google? No. Those tools do not make experts.

Here's another example. Just because everybody has an iPhone doesn't mean you're all amazing photographers getting paid to travel the world. If you have an iPhone with a great camera, and you have an Instagram account, and you have more than 5,000 followers — ask yourself: have you been paid to post something? That would make you a professional. The tools don't make experts. And I promise you that the tools won't provoke your teams to be self-determined and do the work.

As with every tool in human history, how you use it matters more than what it can do. A pen in the hand can be a weapon of inspiration or a weapon of murder. It all depends on who's holding it and what they do with it.

## A Lack of AI Is Not Killing Your Business

Let me be direct about something. If you are sitting here right now and you think you can be replaced by [AI](/topics/ai), then guess what — you can. And if you think your business can be disrupted by AI, it can. AI tools should no longer be seen as innovative. We've quickly moved past the wonder and awe and now towards these tools becoming imperative and necessary to your work.

But — and this is critical — a lack of AI is not killing your business.

A culture of caution is killing your business. Meetings are killing your business. Mediocrity is killing your business. Processes are killing your business. And bad incentives are killing your business.

Our organizations don't need more random AI. We need teams filled with people who have intrinsic motivation to learn, to explore, and to question the status quo — even without the promise of external reward. AI tools make human traits more important and more relevant than ever before.

Those of you sitting pretty, complacent, and calm while the seas of change rage around you are in trouble. Your ship is capsizing and you think that a GPT can direct you back to land successfully. Throwing the latest tools at your existing structures just won't work. Before you can really benefit from the latest AI tools, you need to look internally and rebuild your organization.

## The Antidote Is Curiosity — Not More Tools

So if you tell people what to be curious about, if you tell them how to be curious, if you tell them where to be curious and when to be curious and why to be curious, I can guarantee you that you will kill curiosity in your organization.

Curiosity is an intrinsic motivation to learn. It's a high agency act. To activate your own curious lens, ask yourself in any situation: what can I learn from this? It sounds trivial, but good, bad, up or down — this question provokes more curiosity. And studies have shown that we are better at retaining information and learning when we are curious about the subject matter. If people are obsessed, then they're curious. And if they're free to explore, then they learn more and retain the information.

This is the critical difference the MIT study revealed. People with a strong cognitive baseline — people who were already curious, already engaged, already thinking — showed *higher* neural connectivity when using AI. The tool enhanced what was already there. But for people who had outsourced their thinking entirely, the tool hollowed them out.

AI should amplify human curiosity. It should not replace it. AI should not be leading your actions. It should be enhancing your bias towards action.

## Three Types of Curiosity Your Teams Need

Not all curiosity looks the same, and understanding the types helps you spot where it already exists in your organization — and where it's been suppressed.

**Epistemic curiosity** is the need to understand things deeply. A hunger for knowledge, depth, and truth. This is the person who won't accept the surface-level answer and keeps digging.

**Diversive curiosity** is the "I want something new, something different, something stimulating" type. It's novelty, surprise, a mental restlessness. This is the person who connects unexpected dots across industries.

**Empathetic curiosity** is the need to understand other people — your colleagues, your customers. A desire to understand the thoughts, feelings, and experiences of others.

You might recognize some of these curiosities in yourself. The question is whether your organization rewards them or punishes them.

## Practical Tools for Curiosity-Driven AI Use

### Radical Candor in AI-Augmented Teams

With my teams, we use radical candor — we care about each other personally, but we challenge each other directly. We don't care about ego. You don't have to choose between being a pushover or a jerk. You can be kind and be clear at the same time. This is super important when AI is in the mix, because it's tempting to let the tool smooth over disagreement.

### The Socratic Method Over AI-Generated Answers

Instead of accepting AI outputs at face value, deploy the Socratic method as a reflexive way to challenge your team and engage with problems. Ask open-ended questions. Push deeper with follow-ups. Identify contradictions or vague thinking. Repeat until a clearer, stronger idea emerges.

If something goes wrong, ask: What specifically is down? When did we first notice? What changed around this time? What would be the first thing we'd change if we started over? And one of my favorite questions: who on the team disagrees with our current approach, and why? Inviting dissent is super important.

All of these questions exist to uncover a simple but powerful question: **are we solving the right problem?** No AI tool is asking you that. You have to ask it yourself.

### Cross-Industry Curiosity Beats AI Pattern Matching

The best solutions don't always come from where you expect. Very often it's the smashing together of unexpected things that provide the most interesting solutions. The team at Great Ormond Street Hospital in London were faced with high patient casualty rates during transfers from the operating room to recovery. To solve this, physicians started looking outside their own industry — and found answers in Formula 1 racing team pit stop procedures. They implemented their own version and saw a massive drop in failure rates.

No AI would have made that connection. A curious human did.

---

## FAQ: AI, Curiosity, and Your Organization

**Is AI actually making people dumber?**
Yes — for heavy, uncritical users. MIT brain scans show a 47% reduction in neural connectivity among participants who relied on ChatGPT for cognitive tasks. However, people with a strong cognitive baseline — who used AI as a complement to their own thinking — showed higher neural connectivity. The difference is whether you're using AI to enhance curiosity or replace thinking.

**Should companies ban AI tools?**
No. AI is the largest technological shift in decades and it's not going away. The problem isn't the tool — it's how it's being used. Organizations need to build a culture of curiosity first, then layer AI on top. Without that foundation, AI becomes a crutch that weakens teams rather than strengthening them.

**What is "work slop"?**
Work slop is the output of lazy AI usage — using AI to record meetings, generate notes, create action plans, and tell people what to do next, without any human engagement or critical thinking. It's the work around the work. It looks productive but produces nothing meaningful.

**How do I use AI without losing my ability to think?**
Start with curiosity. Before you prompt an AI tool, ask yourself: what am I trying to learn? Use AI to explore, to challenge your assumptions, to see patterns you might miss — but do the thinking yourself. If you can't explain what the AI generated without looking at it, you haven't learned anything.

**What makes a good AI keynote speaker different from a typical one?**
A good [AI keynote speaker](/speaker) isn't just someone who demonstrates the latest tools. It's someone who has built with AI, understands its limitations, and can help your team develop the human capabilities — curiosity, agency, critical thinking — that make AI actually useful. Tools don't make experts. Culture makes experts who use tools well.

---

## Key Takeaways

- AI tools are causing measurable cognitive decline in heavy users — a 47% reduction in neural connectivity according to MIT brain scans.
- 83% of ChatGPT users couldn't recall an essay they wrote with it just minutes earlier. If your teams are outsourcing thinking to AI, they're not learning.
- The tools are not the differentiator. Everyone has access to the same AI. The team makes the tool, not the other way around.
- A lack of AI is not killing your business. A culture of caution, mediocrity, meetings, and bad incentives is.
- AI should amplify human curiosity, not replace it. Teams with a curious mindset get smarter with AI. Teams without one get dumber.
- Use radical candor and the Socratic method to ensure your teams are engaging critically with AI outputs, not passively accepting them.
- The question no AI is asking you: are we solving the right problem?

---

*Nic Haralambous is an entrepreneur, AI product builder, and [virtual keynote speaker](/speaker) who helps organizations navigate the AI era without losing their ability to think. His keynotes on [AI and product building](/keynotes/ai-and-product-building) combine hands-on builder experience with research-backed frameworks for curiosity-driven innovation. [Book Nic for your next event](/contact).*
